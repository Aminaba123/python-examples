{
 "metadata": {
  "name": "Class 5 - Regression & Regularization"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "!pwd\n!pip install -U scikit-learn\n!pip install -U patsy\n!pip install -U statsmodels",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "/Users/williamliu\r\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Requirement already up-to-date: scikit-learn in ./anaconda/lib/python2.7/site-packages\r\nCleaning up...\r\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Requirement already up-to-date: patsy in ./anaconda/lib/python2.7/site-packages\r\nCleaning up...\r\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Requirement already up-to-date: statsmodels in ./anaconda/lib/python2.7/site-packages\r\nCleaning up...\r\n"
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import statsmodels.formula.api as sm\nimport pandas as pd\n\ndf = pd.read_csv(\"http://data.princeton.edu/wws509/datasets/salary.dat\", sep='\\s+')\n\nmodel = sm.ols(formula=\"sl ~ yr\", data=df).fit()\nmodel.summary()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>           <td>sl</td>        <th>  R-squared:         </th> <td>   0.491</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.481</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   48.22</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Sun, 09 Mar 2014</td> <th>  Prob (F-statistic):</th> <td>7.34e-09</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>14:25:16</td>     <th>  Log-Likelihood:    </th> <td> -507.38</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    52</td>      <th>  AIC:               </th> <td>   1019.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    50</td>      <th>  BIC:               </th> <td>   1023.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n</tr>\n<tr>\n  <th>Intercept</th> <td> 1.817e+04</td> <td> 1003.658</td> <td>   18.100</td> <td> 0.000</td> <td> 1.62e+04  2.02e+04</td>\n</tr>\n<tr>\n  <th>yr</th>        <td>  752.7978</td> <td>  108.409</td> <td>    6.944</td> <td> 0.000</td> <td>  535.051   970.544</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 5.716</td> <th>  Durbin-Watson:     </th> <td>   1.430</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.057</td> <th>  Jarque-Bera (JB):  </th> <td>   5.015</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.509</td> <th>  Prob(JB):          </th> <td>  0.0815</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 4.130</td> <th>  Cond. No.          </th> <td>    15.8</td>\n</tr>\n</table>",
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                     sl   R-squared:                       0.491\nModel:                            OLS   Adj. R-squared:                  0.481\nMethod:                 Least Squares   F-statistic:                     48.22\nDate:                Sun, 09 Mar 2014   Prob (F-statistic):           7.34e-09\nTime:                        14:25:16   Log-Likelihood:                -507.38\nNo. Observations:                  52   AIC:                             1019.\nDf Residuals:                      50   BIC:                             1023.\nDf Model:                           1                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n------------------------------------------------------------------------------\nIntercept   1.817e+04   1003.658     18.100      0.000      1.62e+04  2.02e+04\nyr           752.7978    108.409      6.944      0.000       535.051   970.544\n==============================================================================\nOmnibus:                        5.716   Durbin-Watson:                   1.430\nProb(Omnibus):                  0.057   Jarque-Bera (JB):                5.015\nSkew:                           0.509   Prob(JB):                       0.0815\nKurtosis:                       4.130   Cond. No.                         15.8\n==============================================================================\n\"\"\""
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def summary_df(res):\n    reg_sum = res.summary()\n    a = reg_sum.tables[1]\n    af = [[b.strip() for b in row.split(',')] for row in ('feature'+a.as_csv()).split('\\n')]\n    \n    for wq in af:\n        if size(wq)>6:\n            print wq\n    rf = pd.DataFrame(af[1:], columns=af[0])\n    rf = rf.rename(columns={'P>|t|':'tp', 'std err':'std_err'})\n    rf.coef = rf.coef.astype(float)\n    rf.t = rf.t.astype(float)\n    rf.std_err = rf.std_err.astype(float)\n    rf.tp = rf.tp.astype(float)\n    rf['abs_t'] = rf.t.abs()\n    return rf\n\nsummary_df(model)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>coef</th>\n      <th>std_err</th>\n      <th>t</th>\n      <th>tp</th>\n      <th>[95.0% Conf. Int.]</th>\n      <th>abs_t</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td> Intercept</td>\n      <td> 18170.0000</td>\n      <td> 1003.658</td>\n      <td> 18.100</td>\n      <td> 0</td>\n      <td> 1.62e+04  2.02e+04</td>\n      <td> 18.100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>        yr</td>\n      <td>   752.7978</td>\n      <td>  108.409</td>\n      <td>  6.944</td>\n      <td> 0</td>\n      <td>  535.051   970.544</td>\n      <td>  6.944</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 7 columns</p>\n</div>",
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": "     feature        coef   std_err       t  tp  [95.0% Conf. Int.]   abs_t\n0  Intercept  18170.0000  1003.658  18.100   0  1.62e+04  2.02e+04  18.100\n1         yr    752.7978   108.409   6.944   0   535.051   970.544   6.944\n\n[2 rows x 7 columns]"
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "model = sm.ols(formula=\"sl ~ sx + yr + rk\", data=df).fit()\nmodel.summary()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>           <td>sl</td>        <th>  R-squared:         </th> <td>   0.846</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.833</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   64.64</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Sun, 09 Mar 2014</td> <th>  Prob (F-statistic):</th> <td>1.64e-18</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>14:25:25</td>     <th>  Log-Likelihood:    </th> <td> -476.26</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    52</td>      <th>  AIC:               </th> <td>   962.5</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   972.3</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n</tr>\n<tr>\n  <th>Intercept</th>       <td> 1.643e+04</td> <td>  737.966</td> <td>   22.265</td> <td> 0.000</td> <td> 1.49e+04  1.79e+04</td>\n</tr>\n<tr>\n  <th>sx[T.male]</th>      <td> -524.1492</td> <td>  834.687</td> <td>   -0.628</td> <td> 0.533</td> <td>-2203.323  1155.024</td>\n</tr>\n<tr>\n  <th>rk[T.associate]</th> <td> 4373.9154</td> <td>  906.124</td> <td>    4.827</td> <td> 0.000</td> <td> 2551.030  6196.801</td>\n</tr>\n<tr>\n  <th>rk[T.full]</th>      <td> 9483.8419</td> <td>  912.795</td> <td>   10.390</td> <td> 0.000</td> <td> 7647.536  1.13e+04</td>\n</tr>\n<tr>\n  <th>yr</th>              <td>  390.9358</td> <td>   75.383</td> <td>    5.186</td> <td> 0.000</td> <td>  239.285   542.587</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>23.039</td> <th>  Durbin-Watson:     </th> <td>   1.832</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  38.727</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 1.410</td> <th>  Prob(JB):          </th> <td>3.90e-09</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 6.150</td> <th>  Cond. No.          </th> <td>    32.3</td>\n</tr>\n</table>",
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                     sl   R-squared:                       0.846\nModel:                            OLS   Adj. R-squared:                  0.833\nMethod:                 Least Squares   F-statistic:                     64.64\nDate:                Sun, 09 Mar 2014   Prob (F-statistic):           1.64e-18\nTime:                        14:25:25   Log-Likelihood:                -476.26\nNo. Observations:                  52   AIC:                             962.5\nDf Residuals:                      47   BIC:                             972.3\nDf Model:                           4                                         \n===================================================================================\n                      coef    std err          t      P>|t|      [95.0% Conf. Int.]\n-----------------------------------------------------------------------------------\nIntercept        1.643e+04    737.966     22.265      0.000      1.49e+04  1.79e+04\nsx[T.male]       -524.1492    834.687     -0.628      0.533     -2203.323  1155.024\nrk[T.associate]  4373.9154    906.124      4.827      0.000      2551.030  6196.801\nrk[T.full]       9483.8419    912.795     10.390      0.000      7647.536  1.13e+04\nyr                390.9358     75.383      5.186      0.000       239.285   542.587\n==============================================================================\nOmnibus:                       23.039   Durbin-Watson:                   1.832\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               38.727\nSkew:                           1.410   Prob(JB):                     3.90e-09\nKurtosis:                       6.150   Cond. No.                         32.3\n==============================================================================\n\"\"\""
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "df.groupby('rk').sl.count()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": "rk\nassistant    18\nassociate    14\nfull         20\ndtype: int64"
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from patsy import dmatrices\n\ny, X = dmatrices('sl ~ sx + yr + rk', data=df, return_type='dataframe')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "y.head",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": "<bound method DataFrame.head of        sl\n0   36350\n1   35350\n2   28200\n3   26775\n4   33696\n5   28516\n6   24900\n7   31909\n8   31850\n9   32850\n10  27025\n11  24750\n12  28200\n13  23712\n14  25748\n15  29342\n16  31114\n17  24742\n18  22906\n19  24450\n20  19175\n21  20525\n22  27959\n23  38045\n24  24832\n25  25400\n26  24800\n27  25500\n28  26182\n29  23725\n30  21600\n31  23300\n32  23713\n33  20690\n34  22450\n35  20850\n36  18304\n37  17095\n38  16700\n39  17600\n40  18075\n41  18000\n42  20999\n43  17250\n44  16500\n45  16094\n46  16150\n47  15350\n48  16244\n49  16686\n50  15000\n51  20300\n\n[52 rows x 1 columns]>"
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "X.head()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Intercept</th>\n      <th>sx[T.male]</th>\n      <th>rk[T.associate]</th>\n      <th>rk[T.full]</th>\n      <th>yr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td> 1</td>\n      <td> 1</td>\n      <td> 0</td>\n      <td> 1</td>\n      <td> 25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td> 1</td>\n      <td> 1</td>\n      <td> 0</td>\n      <td> 1</td>\n      <td> 13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td> 1</td>\n      <td> 1</td>\n      <td> 0</td>\n      <td> 1</td>\n      <td> 10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td> 1</td>\n      <td> 0</td>\n      <td> 0</td>\n      <td> 1</td>\n      <td>  7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td> 1</td>\n      <td> 1</td>\n      <td> 0</td>\n      <td> 1</td>\n      <td> 19</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 5 columns</p>\n</div>",
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": "   Intercept  sx[T.male]  rk[T.associate]  rk[T.full]  yr\n0          1           1                0           1  25\n1          1           1                0           1  13\n2          1           1                0           1  10\n3          1           0                0           1   7\n4          1           1                0           1  19\n\n[5 rows x 5 columns]"
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel = model.fit(X,y)\nmodel.score(X,y)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": "0.8461760134902937"
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print X.columns",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Index([u'Intercept', u'sx[T.male]', u'rk[T.associate]', u'rk[T.full]', u'yr'], dtype='object')\n"
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "df['pred'] = model.predict(X)\nprint df.head()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "       sx    rk  yr         dg  yd     sl          pred\n0    male  full  25  doctorate  35  36350  35164.048275\n1    male  full  13  doctorate  22  35350  30472.819188\n2    male  full  10  doctorate  23  28200  29300.011916\n3  female  full   7  doctorate  27  26775  28651.353854\n4    male  full  19    masters  30  33696  32818.433731\n\n[5 rows x 7 columns]\n"
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print model.coef_ # Using mean absolute error",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[[    0.          -524.14921086  4373.91539051  9483.84186941\n    390.93575731]]\n"
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": "from sklearn.metrics import mean_absolute_error\n\nmean_absolute_error(model.predict(X), y) # on average, about $1638 off from salary prediction",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": "1638.0060186013989"
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn import linear_model\n\nmodel = linear_model.Ridge(alpha = .5) # Ridge Regression (L2), alpha is the lambda / how much to regularize the numbers\nmodel.fit(X,y)\n# Everything is closer to 1 now\nprint model.coef_ # The model's coefficients",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[[    0.          -421.25668145  3779.9005536   8721.66041047\n    417.42257364]]\n"
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn import linear_model\n\n\nmodel = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0]) # Ridge Regression (L2) with cross-validation and different alphas\nmodel.fit(X,y)\n# The higher the alpha, the higher the bias, lower the variance\nprint model.coef_",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[[    0.          -501.05001107  4243.95176783  9319.37677802\n    396.62263309]]\n"
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn import linear_model\n\nmodel = linear_model.RidgeCV(alphas=[0.1, 0.5, 0.9]) # Ridge Regression (L2) with cross-validation and different alphas\nmodel.fit(X,y)\n# The higher the alpha, the higher the bias, lower the variance\nprint model.coef_",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[[    0.          -501.05001107  4243.95176783  9319.37677802\n    396.62263309]]\n"
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print model.alpha_",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "0.1\n"
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print model.fit",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "<bound method RidgeCV.fit of RidgeCV(alphas=[0.1, 0.5, 0.9], cv=None, fit_intercept=True, gcv_mode=None,\n    loss_func=None, normalize=False, score_func=None, scoring=None,\n    store_cv_values=False)>\n"
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn.cross_validation import train_test_split\n\ntrain, test = train_test_split(df, test_size=0.25)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print train",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[['male' 'associate' 11 'doctorate' 14 24800 24581.02119399159]\n ['male' 'associate' 3 'masters' 17 23725 21453.535135486803]\n ['male' 'associate' 11 'masters' 31 23300 24581.02119399159]\n ['male' 'associate' 3 'masters' 7 26182 21453.535135486803]\n ['male' 'assistant' 16 'masters' 23 19175 22161.784590046802]\n ['female' 'assistant' 8 'doctorate' 14 18304 19558.447742397977]\n ['male' 'associate' 10 'masters' 15 22906 24190.08543667849]\n ['male' 'associate' 0 'doctorate' 7 20999 20280.727863547505]\n ['female' 'associate' 6 'masters' 29 22450 23150.491618282067]\n ['male' 'assistant' 3 'doctorate' 4 18075 17079.619744976513]\n ['female' 'full' 8 'doctorate' 24 38045 29042.289611805056]\n ['male' 'full' 13 'masters' 31 32850 30472.819187514586]\n ['male' 'full' 10 'doctorate' 23 28200 29300.01191557529]\n ['female' 'full' 7 'doctorate' 27 26775 28651.353854491957]\n ['female' 'associate' 4 'masters' 33 20690 22368.620103655867]\n ['male' 'assistant' 4 'doctorate' 4 17600 17470.55550228961]\n ['male' 'associate' 8 'masters' 31 20525 23408.213922052295]\n ['male' 'assistant' 2 'doctorate' 1 16094 16688.683987663415]\n ['female' 'assistant' 2 'doctorate' 2 15350 17212.83319851938]\n ['female' 'assistant' 3 'doctorate' 3 17250 17603.768955832482]\n ['male' 'full' 7 'doctorate' 15 29342 28127.204643635992]\n ['male' 'associate' 1 'doctorate' 9 20850 20671.663620860603]\n ['male' 'full' 16 'doctorate' 21 28516 31645.62645945388]\n ['male' 'full' 7 'doctorate' 13 27959 28127.204643635992]\n ['male' 'full' 16 'doctorate' 18 31909 31645.62645945388]\n ['male' 'assistant' 4 'doctorate' 4 17095 17470.55550228961]\n ['male' 'full' 13 'doctorate' 22 35350 30472.819187514586]\n ['male' 'assistant' 1 'doctorate' 1 16244 16297.748230350317]\n ['female' 'assistant' 1 'doctorate' 1 16686 16821.89744120628]\n ['female' 'full' 0 'masters' 32 24900 25914.803553300266]\n ['male' 'full' 19 'masters' 30 33696 32818.433731393176]\n ['male' 'full' 13 'doctorate' 20 31114 30472.819187514586]\n ['male' 'assistant' 2 'doctorate' 3 16500 16688.683987663415]\n ['male' 'full' 5 'doctorate' 18 25400 27345.333129009792]\n ['male' 'associate' 9 'masters' 27 23712 23799.149679365393]\n ['male' 'full' 9 'doctorate' 17 28200 28909.07615826219]\n ['male' 'full' 12 'doctorate' 22 27025 30081.883430201487]\n ['male' 'full' 25 'doctorate' 35 36350 35164.04827527177]\n ['male' 'full' 6 'masters' 21 24450 27736.26888632289]]\n"
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print test",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[['female' 'full' 5 'doctorate' 16 25500 27869.48233986576]\n ['male' 'associate' 9 'doctorate' 12 24832 23799.149679365393]\n ['female' 'assistant' 1 'doctorate' 1 15000 16821.89744120628]\n ['male' 'assistant' 3 'masters' 11 18000 17079.619744976513]\n ['male' 'associate' 11 'masters' 14 24742 24581.02119399159]\n ['male' 'assistant' 4 'doctorate' 5 16700 17470.55550228961]\n ['male' 'associate' 15 'doctorate' 19 24750 26144.76422324399]\n ['male' 'full' 13 'masters' 30 31850 30472.819187514586]\n ['female' 'assistant' 0 'doctorate' 2 20300 16430.961683893183]\n ['female' 'assistant' 10 'masters' 15 21600 20340.319257024174]\n ['male' 'full' 9 'doctorate' 24 25748 28909.07615826219]\n ['male' 'assistant' 9 'masters' 14 23713 19425.234288855107]\n ['female' 'assistant' 2 'doctorate' 6 16150 17212.83319851938]]\n"
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn.cross_validation import train_test_split\n\ntrain, test = train_test_split(df, test_size=0.10)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print train",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[['male' 'associate' 11 'doctorate' 14 24800 24581.02119399159]\n ['male' 'assistant' 3 'doctorate' 4 18075 17079.619744976513]\n ['female' 'assistant' 8 'doctorate' 14 18304 19558.447742397977]\n ['female' 'assistant' 0 'doctorate' 2 20300 16430.961683893183]\n ['male' 'associate' 3 'masters' 17 23725 21453.535135486803]\n ['male' 'assistant' 2 'doctorate' 1 16094 16688.683987663415]\n ['male' 'assistant' 1 'doctorate' 1 16244 16297.748230350317]\n ['female' 'assistant' 10 'masters' 15 21600 20340.319257024174]\n ['male' 'full' 12 'doctorate' 22 27025 30081.883430201487]\n ['male' 'full' 13 'masters' 31 32850 30472.819187514586]\n ['male' 'associate' 1 'doctorate' 9 20850 20671.663620860603]\n ['male' 'full' 13 'doctorate' 22 35350 30472.819187514586]\n ['male' 'assistant' 3 'masters' 11 18000 17079.619744976513]\n ['male' 'full' 19 'masters' 30 33696 32818.433731393176]\n ['female' 'assistant' 2 'doctorate' 2 15350 17212.83319851938]\n ['male' 'full' 6 'masters' 21 24450 27736.26888632289]\n ['male' 'assistant' 9 'masters' 14 23713 19425.234288855107]\n ['male' 'full' 9 'doctorate' 17 28200 28909.07615826219]\n ['male' 'associate' 11 'masters' 14 24742 24581.02119399159]\n ['male' 'full' 16 'doctorate' 21 28516 31645.62645945388]\n ['male' 'full' 13 'doctorate' 20 31114 30472.819187514586]\n ['male' 'associate' 0 'doctorate' 7 20999 20280.727863547505]\n ['male' 'full' 7 'doctorate' 13 27959 28127.204643635992]\n ['female' 'associate' 6 'masters' 29 22450 23150.491618282067]\n ['male' 'full' 7 'doctorate' 15 29342 28127.204643635992]\n ['male' 'assistant' 4 'doctorate' 4 17095 17470.55550228961]\n ['male' 'full' 25 'doctorate' 35 36350 35164.04827527177]\n ['male' 'full' 16 'doctorate' 18 31909 31645.62645945388]\n ['male' 'associate' 11 'masters' 31 23300 24581.02119399159]\n ['female' 'full' 0 'masters' 32 24900 25914.803553300266]\n ['male' 'assistant' 2 'doctorate' 3 16500 16688.683987663415]\n ['male' 'assistant' 16 'masters' 23 19175 22161.784590046802]\n ['male' 'full' 13 'masters' 30 31850 30472.819187514586]\n ['male' 'assistant' 4 'doctorate' 5 16700 17470.55550228961]\n ['female' 'full' 5 'doctorate' 16 25500 27869.48233986576]\n ['male' 'associate' 9 'doctorate' 12 24832 23799.149679365393]\n ['female' 'associate' 4 'masters' 33 20690 22368.620103655867]\n ['female' 'full' 7 'doctorate' 27 26775 28651.353854491957]\n ['male' 'associate' 10 'masters' 15 22906 24190.08543667849]\n ['female' 'assistant' 3 'doctorate' 3 17250 17603.768955832482]\n ['male' 'full' 10 'doctorate' 23 28200 29300.01191557529]\n ['female' 'assistant' 2 'doctorate' 6 16150 17212.83319851938]\n ['male' 'associate' 3 'masters' 7 26182 21453.535135486803]\n ['male' 'full' 5 'doctorate' 18 25400 27345.333129009792]\n ['male' 'associate' 8 'masters' 31 20525 23408.213922052295]\n ['male' 'associate' 9 'masters' 27 23712 23799.149679365393]]\n"
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print test",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[['female' 'full' 8 'doctorate' 24 38045 29042.289611805056]\n ['female' 'assistant' 1 'doctorate' 1 15000 16821.89744120628]\n ['male' 'associate' 15 'doctorate' 19 24750 26144.76422324399]\n ['male' 'assistant' 4 'doctorate' 4 17600 17470.55550228961]\n ['male' 'full' 9 'doctorate' 24 25748 28909.07615826219]\n ['female' 'assistant' 1 'doctorate' 1 16686 16821.89744120628]]\n"
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from patsy import dmatrices\n\nX, y = dmatrices('sl ~ sx + yr + rk', data=df, return_type='dataframe')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel = model.fit(X,y)\nmodel.score(X,y)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": "0.48606533149600384"
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}